{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SETUP ENVIRONMENT\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# # Set Java (SỬA PATH NÀY!)\n",
    "os.environ['JAVA_HOME'] = 'C:\\\\Java\\\\jdk-1.8'\n",
    "\n",
    "# # QUAN TRỌNG: Bypass Hadoop requirement\n",
    "os.environ['HADOOP_HOME'] = os.environ.get('JAVA_HOME')\n",
    "os.environ['PATH'] = f\"{os.environ['JAVA_HOME']}\\\\bin;{os.environ.get('PATH', '')}\"\n",
    "\n",
    "print(f\" JAVA_HOME: {os.environ['JAVA_HOME']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALL PACKAGES\n",
    "!pip install pyspark findspark matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style cho plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE SPARK SESSION\n",
    "import tempfile\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"YouTubeTimeAnalysis\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", tempfile.gettempdir()) \\\n",
    "    .config(\"spark.ui.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(f\"Spark {spark.version} started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PREPROCESSED DATA\n",
    "df = spark.read.csv(\"./data/preprocessed_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "print(f\" Loaded {df.count():,} rows with {len(df.columns)} columns\")\n",
    "print(\"\\nSAMPLE DATA\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPARATION\n",
    "\n",
    "# Convert timestamps\n",
    "df = df.withColumn('trending_date', to_timestamp('trending_date'))\n",
    "df = df.withColumn('publishedAt', to_timestamp('publishedAt'))\n",
    "\n",
    "# Extract time features\n",
    "df = df.withColumn('publish_hour', hour('publishedAt'))\n",
    "df = df.withColumn('publish_day', date_format('publishedAt', 'E'))  # Mon, Tue, Wed\n",
    "df = df.withColumn('publish_date', to_date('publishedAt'))\n",
    "df = df.withColumn('trending_day', date_format('trending_date', 'E'))\n",
    "df = df.withColumn('trending_month', month('trending_date'))\n",
    "df = df.withColumn('trending_year', year('trending_date'))\n",
    "\n",
    "print(\" Time features extracted\")\n",
    "df.select('video_id', 'publishedAt', 'publish_hour', 'publish_day').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dac1f9-05ed-4582-a85f-a1db29b78a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm đoạn này vào cuối cell 'prepare_data'\n",
    "df = df.withColumn(\"category_name\", \n",
    "    when(col(\"categoryId\") == \"1\", \"Film & Animation\")\n",
    "    .when(col(\"categoryId\") == \"2\", \"Autos & Vehicles\")\n",
    "    .when(col(\"categoryId\") == \"10\", \"Music\")\n",
    "    .when(col(\"categoryId\") == \"15\", \"Pets & Animals\")\n",
    "    .when(col(\"categoryId\") == \"17\", \"Sports\")\n",
    "    .when(col(\"categoryId\") == \"19\", \"Travel & Events\")\n",
    "    .when(col(\"categoryId\") == \"20\", \"Gaming\")\n",
    "    .when(col(\"categoryId\") == \"22\", \"People & Blogs\")\n",
    "    .when(col(\"categoryId\") == \"23\", \"Comedy\")\n",
    "    .when(col(\"categoryId\") == \"24\", \"Entertainment\")\n",
    "    .when(col(\"categoryId\") == \"25\", \"News & Politics\")\n",
    "    .when(col(\"categoryId\") == \"26\", \"Howto & Style\")\n",
    "    .when(col(\"categoryId\") == \"27\", \"Education\")\n",
    "    .when(col(\"categoryId\") == \"28\", \"Science & Technology\")\n",
    "    .otherwise(\"Unknown\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efd2e2-8461-4c98-9491-20bb37f7f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BƯỚC CHUẨN BỊ BỔ SUNG: TẠO DF VỚI METRICS\n",
    "# Cần DF này cho phân tích engagement theo giờ\n",
    "\n",
    "# print(\" CHUẨN BỊ BỔ SUNG: Tạo DF metrics độc nhất\")\n",
    "\n",
    "# Convert metrics\n",
    "df_with_metrics = df.withColumn(\"view_count_num\", col(\"view_count\").cast(\"long\")) \\\n",
    "    .withColumn(\"likes_num\", col(\"likes\").cast(\"long\")) \\\n",
    "    .withColumn(\"dislikes_num\", col(\"dislikes\").cast(\"long\")) \\\n",
    "    .withColumn(\"comment_count_num\", col(\"comment_count\").cast(\"long\"))\n",
    "\n",
    "# Lấy view/like/comment cao nhất cho mỗi video\n",
    "window_spec_metrics = Window.partitionBy(\"video_id\").orderBy(desc(\"view_count_num\"))\n",
    "df_unique_with_metrics = df_with_metrics.withColumn(\"rank\", row_number().over(window_spec_metrics)) \\\n",
    "    .filter(col(\"rank\") == 1) \\\n",
    "    .drop(\"rank\")\n",
    "\n",
    "print(f\"Đã tạo df_unique_with_metrics với {df_unique_with_metrics.count()} video độc nhất\")\n",
    "# df_unique_with_metrics giờ đã có publish_hour, view_count_num, likes_num\n",
    "df_unique_with_metrics.select(\"video_id\", \"publish_hour\", \"view_count_num\", \"likes_num\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHÂN TÍCH 1: HOURLY UPLOAD PATTERNS\n",
    "\n",
    "print(\"HOURLY UPLOAD PATTERNS\")\n",
    "\n",
    "# Group by publish hour\n",
    "hourly_analysis = df.groupBy('publish_hour') \\\n",
    "    .count() \\\n",
    "    .orderBy('publish_hour')\n",
    "\n",
    "print(\"\\n Videos by Upload Hour:\")\n",
    "hourly_analysis.show(24)\n",
    "\n",
    "# Convert to Pandas for plotting\n",
    "hourly_analysis_pd = hourly_analysis.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(hourly_analysis_pd['publish_hour'], hourly_analysis_pd['count'], color='steelblue', alpha=0.8)\n",
    "plt.xlabel('Hour of Day (0-23)', fontsize=12)\n",
    "plt.ylabel('Number of Videos', fontsize=12)\n",
    "plt.title('Video Upload Distribution by Hour', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, row in hourly_analysis_pd.iterrows():\n",
    "    plt.text(row['publish_hour'], row['count'] + 100, f\"{row['count']:,}\", \n",
    "             ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find peak hours\n",
    "peak_hour = hourly_analysis_pd.loc[hourly_analysis_pd['count'].idxmax()]\n",
    "low_hour = hourly_analysis_pd.loc[hourly_analysis_pd['count'].idxmin()]\n",
    "\n",
    "print(f\"\\nPeak upload hour: {int(peak_hour['publish_hour'])}:00 ({peak_hour['count']:,} videos)\")\n",
    "print(f\"Lowest upload hour: {int(low_hour['publish_hour'])}:00 ({low_hour['count']:,} videos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHÂN TÍCH 2: DAY OF WEEK PATTERNS\n",
    "\n",
    "print(\" DAY OF WEEK PATTERNS\")\n",
    "\n",
    "# Group by day of week\n",
    "dow_analysis = df.groupBy('publish_day') \\\n",
    "    .count() \\\n",
    "    .orderBy('count', ascending=False)\n",
    "\n",
    "print(\"\\n Videos by Day of Week:\")\n",
    "dow_analysis.show()\n",
    "\n",
    "# Convert to Pandas\n",
    "dow_analysis_pd = dow_analysis.toPandas()\n",
    "\n",
    "# Reorder days properly\n",
    "day_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "dow_analysis_pd['publish_day'] = pd.Categorical(\n",
    "    dow_analysis_pd['publish_day'], \n",
    "    categories=day_order, \n",
    "    ordered=True\n",
    ")\n",
    "dow_analysis_pd = dow_analysis_pd.sort_values('publish_day')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "bars = plt.bar(dow_analysis_pd['publish_day'], dow_analysis_pd['count'], \n",
    "               color='coral', alpha=0.8)\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.ylabel('Number of Videos', fontsize=12)\n",
    "plt.title('Video Upload Distribution by Day of Week', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 100,\n",
    "             f'{int(height):,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find peak day\n",
    "peak_day = dow_analysis_pd.loc[dow_analysis_pd['count'].idxmax()]\n",
    "print(f\"\\nPeak upload day: {peak_day['publish_day']} ({peak_day['count']:,} videos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trending_dow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHÂN TÍCH 3: TRENDING DAY PATTERNS\n",
    "\n",
    "print(\"TRENDING DAY PATTERNS\")\n",
    "\n",
    "# Group by trending day\n",
    "trending_dow = df.groupBy('trending_day') \\\n",
    "    .count() \\\n",
    "    .orderBy('count', ascending=False)\n",
    "\n",
    "print(\"\\nVideos by Trending Day:\")\n",
    "trending_dow.show()\n",
    "\n",
    "trending_dow_pd = trending_dow.toPandas()\n",
    "trending_dow_pd['trending_day'] = pd.Categorical(\n",
    "    trending_dow_pd['trending_day'],\n",
    "    categories=day_order,\n",
    "    ordered=True\n",
    ")\n",
    "trending_dow_pd = trending_dow_pd.sort_values('trending_day')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(trending_dow_pd['trending_day'], trending_dow_pd['count'], \n",
    "        color='green', alpha=0.7)\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.ylabel('Number of Videos', fontsize=12)\n",
    "plt.title('Trending Videos by Day of Week', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "time_to_trend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHÂN TÍCH 4: TIME TO TRENDING\n",
    "\n",
    "print(\"TIME TO TRENDING ANALYSIS\")\n",
    "\n",
    "# Calculate days from publish to trending\n",
    "df_time = df.withColumn(\n",
    "    'days_to_trend',\n",
    "    datediff(col('trending_date'), col('publishedAt'))\n",
    ")\n",
    "\n",
    "# Get first trending date for each video\n",
    "window_spec = Window.partitionBy('video_id').orderBy('trending_date')\n",
    "df_first_trend = df_time.withColumn('rank', row_number().over(window_spec)) \\\n",
    "    .filter(col('rank') == 1) \\\n",
    "    .drop('rank')\n",
    "\n",
    "# Statistics\n",
    "stats = df_first_trend.select(\n",
    "    avg('days_to_trend').alias('avg_days'),\n",
    "    expr('percentile_approx(days_to_trend, 0.5)').alias('median_days'),\n",
    "    min('days_to_trend').alias('min_days'),\n",
    "    max('days_to_trend').alias('max_days')\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nTime to Trending Statistics:\")\n",
    "print(f\"   Average: {stats['avg_days']:.1f} days\")\n",
    "print(f\"   Median: {stats['median_days']} days\")\n",
    "print(f\"   Min: {stats['min_days']} days\")\n",
    "print(f\"   Max: {stats['max_days']} days\")\n",
    "\n",
    "# Distribution\n",
    "days_dist = df_first_trend.groupBy('days_to_trend') \\\n",
    "    .count() \\\n",
    "    .orderBy('days_to_trend') \\\n",
    "    .limit(30)\n",
    "\n",
    "days_dist_pd = days_dist.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(days_dist_pd['days_to_trend'], days_dist_pd['count'], color='purple', alpha=0.7)\n",
    "plt.xlabel('Days from Upload to Trending', fontsize=12)\n",
    "plt.ylabel('Number of Videos', fontsize=12)\n",
    "plt.title('Distribution: Days from Upload to First Trending', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Same-day trending\n",
    "same_day = df_first_trend.filter(col('days_to_trend') == 0).count()\n",
    "total = df_first_trend.count()\n",
    "pct = (same_day / total * 100)\n",
    "\n",
    "print(f\"\\nSame-day trending: {same_day:,} videos ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHÂN TÍCH 5: HOUR x DAY HEATMAP\n",
    "\n",
    "print(\"UPLOAD PATTERNS: HOUR x DAY HEATMAP\")\n",
    "\n",
    "# Create pivot table\n",
    "hour_day = df.groupBy('publish_hour', 'publish_day') \\\n",
    "    .count() \\\n",
    "    .toPandas()\n",
    "\n",
    "pivot = hour_day.pivot(index='publish_hour', \n",
    "                        columns='publish_day', \n",
    "                        values='count').fillna(0)\n",
    "\n",
    "# Reorder columns\n",
    "pivot = pivot[day_order]\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(pivot, annot=True, fmt='.0f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Number of Videos'})\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.ylabel('Hour of Day', fontsize=12)\n",
    "plt.title('Upload Activity Heatmap: Hour x Day', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find peak hour-day combination\n",
    "max_idx = pivot.stack().idxmax()\n",
    "max_val = pivot.stack().max()\n",
    "print(f\"\\nPeak activity: {max_idx[1]} at {int(max_idx[0])}:00 ({max_val:.0f} videos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6db3b3-6f56-4ebd-b599-e66d16dec728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHÂN TÍCH BỔ SUNG 1: TIME-TO-TREND THEO THỂ LOẠI\n",
    "# Mục đích: Xem thể loại nào \"bùng nổ\" nhanh nhất.\n",
    "\n",
    "print(\"PHÂN TÍCH BỔ SUNG: TIME-TO-TREND THEO THỂ LOẠI\")\n",
    "\n",
    "# df_first_trend đã được tạo ở Phân tích 4\n",
    "# Và df đã được map category_name (từ bước 1)\n",
    "\n",
    "time_to_trend_category = df_first_trend.groupBy(\"category_name\") \\\n",
    "    .agg(\n",
    "        avg(\"days_to_trend\").alias(\"avg_days_to_trend\"),\n",
    "        expr(\"percentile_approx(days_to_trend, 0.5)\").alias(\"median_days_to_trend\")\n",
    "    ) \\\n",
    "    .orderBy(\"avg_days_to_trend\") # Sắp xếp theo ngày trung bình TĂNG DẦN\n",
    "\n",
    "print(\"Thời gian trung bình để lên Top Trending theo Thể loại (Nhanh nhất -> Chậm nhất)\")\n",
    "time_to_trend_category.show()\n",
    "\n",
    "# Plotting\n",
    "time_trend_cat_pd = time_to_trend_category.toPandas()\n",
    "plt.figure(figsize=(15, 7))\n",
    "bars = plt.bar(time_trend_cat_pd['category_name'], time_trend_cat_pd['avg_days_to_trend'])\n",
    "plt.title('Thời gian trung bình lên Top Trending (theo Thể loại)', fontsize=16)\n",
    "plt.xlabel('Thể loại')\n",
    "plt.ylabel('Số ngày trung bình')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Insight: 'News & Politics' và 'Music' (cho MV mới) thường có\")\n",
    "print(\"thời gian lên top rất ngắn (trung bình 1-2 ngày).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa2072-48ff-444c-9b7d-d97fe763eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHÂN TÍCH BỔ SUNG 2: TƯƠNG TÁC THEO GIỜ ĐĂNG\n",
    "# Mục đích: Giờ nào đăng video thì hiệu quả (nhiều tương tác) nhất?\n",
    "\n",
    "print(\"PHÂN TÍCH BỔ SUNG: TƯƠNG TÁC THEO GIỜ ĐĂNG\")\n",
    "\n",
    "# Sử dụng df_unique_with_metrics từ cell chuẩn bị bổ sung\n",
    "engagement_by_hour = df_unique_with_metrics.groupBy(\"publish_hour\") \\\n",
    "    .agg(\n",
    "        avg(\"view_count_num\").alias(\"avg_views\"),\n",
    "        avg(\"likes_num\").alias(\"avg_likes\"),\n",
    "        avg(\"comment_count_num\").alias(\"avg_comments\")\n",
    "    ) \\\n",
    "    .orderBy(\"publish_hour\")\n",
    "\n",
    "print(\"Tương tác trung bình theo giờ đăng video\")\n",
    "engagement_by_hour.show(24)\n",
    "\n",
    "# Plotting\n",
    "engagement_hour_pd = engagement_by_hour.toPandas()\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 15), sharex=True)\n",
    "fig.suptitle('Tương tác trung bình theo Giờ đăng video', fontsize=16, y=1.02)\n",
    "\n",
    "sns.lineplot(data=engagement_hour_pd, x='publish_hour', y='avg_views', ax=axes[0], marker='o')\n",
    "axes[0].set_title('Lượt xem trung bình')\n",
    "axes[0].set_ylabel('Avg Views')\n",
    "axes[0].grid(axis='both', alpha=0.3)\n",
    "\n",
    "sns.lineplot(data=engagement_hour_pd, x='publish_hour', y='avg_likes', ax=axes[1], marker='o', color='green')\n",
    "axes[1].set_title('Likes trung bình')\n",
    "axes[1].set_ylabel('Avg Likes')\n",
    "axes[1].grid(axis='both', alpha=0.3)\n",
    "\n",
    "sns.lineplot(data=engagement_hour_pd, x='publish_hour', y='avg_comments', ax=axes[2], marker='o', color='red')\n",
    "axes[2].set_title('Comments trung bình')\n",
    "axes[2].set_ylabel('Avg Comments')\n",
    "axes[2].grid(axis='both', alpha=0.3)\n",
    "\n",
    "plt.xlabel('Giờ đăng (0-23)')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\" Insight: So sánh biểu đồ này với biểu đồ 'SỐ LƯỢNG video' theo giờ.\")\n",
    "print(\" Có thể giờ đăng nhiều nhất (cao điểm) không phải là giờ có tương tác trung bình cao nhất.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aff0133-6c72-4f6b-88ab-9b2eeabf02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHÂN TÍCH BỔ SUNG 3: \"TUỔI THỌ\" TRENDING\n",
    "# Mục đích: Video trụ lại top trending trong bao lâu?\n",
    "\n",
    "print(\"PHÂN TÍCH BỔ SUNG: TUỔI THỌ TRENDING\")\n",
    "\n",
    "# Sử dụng df (đã map category_name)\n",
    "# Tính số ngày trending cho mỗi video\n",
    "trending_lifespan_video = df.groupBy(\"video_id\", \"category_name\") \\\n",
    "    .agg(\n",
    "        (datediff(max(\"trending_date\"), min(\"trending_date\")) + 1).alias(\"days_on_trending\")\n",
    "    )\n",
    "\n",
    "# Tính trung bình theo thể loại\n",
    "trending_lifespan_category = trending_lifespan_video.groupBy(\"category_name\") \\\n",
    "    .agg(\n",
    "        avg(\"days_on_trending\").alias(\"avg_trending_lifespan\"),\n",
    "        expr(\"percentile_approx(days_on_trending, 0.5)\").alias(\"median_trending_lifespan\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"avg_trending_lifespan\"))\n",
    "\n",
    "print(\"Tuổi thọ trung bình trên Top Trending (theo Thể loại)\")\n",
    "trending_lifespan_category.show()\n",
    "\n",
    "# Plotting\n",
    "lifespan_pd = trending_lifespan_category.toPandas()\n",
    "plt.figure(figsize=(15, 7))\n",
    "bars = plt.bar(lifespan_pd['category_name'], lifespan_pd['avg_trending_lifespan'])\n",
    "plt.title('Tuổi thọ trung bình trên Top Trending (theo Thể loại)', fontsize=16)\n",
    "plt.xlabel('Thể loại')\n",
    "plt.ylabel('Số ngày trung bình')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Insight: Các video 'Music' có thể bùng nổ nhanh nhưng cũng 'nguội' nhanh,\")\n",
    "print(\"trong khi 'Gaming' hoặc 'Howto' có thể trụ lại lâu hơn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT TIME BASELINE FOR REAL-TIME MONITORING\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"EXPORTING TIME BASELINE METRICS\")\n",
    "\n",
    "# Thu thập time-based metrics\n",
    "baseline_time_metrics = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'analysis_type': 'time_analysis',\n",
    "    \n",
    "    # 1. Hourly patterns\n",
    "    'hourly_distribution': {\n",
    "        'video_count_by_hour': hourly_analysis_pd.set_index('publish_hour')['count'].to_dict(),\n",
    "        'peak_hours': hourly_analysis_pd.nlargest(3, 'count')['publish_hour'].astype(int).tolist(),\n",
    "        'low_hours': hourly_analysis_pd.nsmallest(3, 'count')['publish_hour'].astype(int).tolist()\n",
    "    },\n",
    "    \n",
    "    # 2. Day of week patterns\n",
    "    'daily_distribution': {\n",
    "        'video_count_by_day': dow_analysis_pd.set_index('publish_day')['count'].to_dict(),\n",
    "        'peak_days': dow_analysis_pd.nlargest(3, 'count')['publish_day'].tolist(),\n",
    "        'low_days': dow_analysis_pd.nsmallest(3, 'count')['publish_day'].tolist()\n",
    "    },\n",
    "    \n",
    "    # 3. Trending day patterns\n",
    "    'trending_distribution': {\n",
    "        'video_count_by_trending_day': trending_dow_pd.set_index('trending_day')['count'].to_dict()\n",
    "    },\n",
    "    \n",
    "    # 4. Time to trending\n",
    "    'time_to_trend': {\n",
    "        'avg_days': float(stats['avg_days']),\n",
    "        'median_days': int(stats['median_days']),\n",
    "        'min_days': int(stats['min_days']),\n",
    "        'max_days': int(stats['max_days']),\n",
    "        'same_day_percentage': float(pct)\n",
    "    },\n",
    "    \n",
    "    # 5. Statistical summary\n",
    "    'statistics': {\n",
    "        'most_active_hour': int(hourly_analysis_pd.loc[hourly_analysis_pd['count'].idxmax(), 'publish_hour']),\n",
    "        'least_active_hour': int(hourly_analysis_pd.loc[hourly_analysis_pd['count'].idxmin(), 'publish_hour']),\n",
    "        'most_active_day': str(dow_analysis_pd.loc[dow_analysis_pd['count'].idxmax(), 'publish_day']),\n",
    "        'avg_videos_per_hour': float(hourly_analysis_pd['count'].mean()),\n",
    "        'avg_videos_per_day': float(dow_analysis_pd['count'].mean())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Lưu vào file JSON\n",
    "os.makedirs('./data/baselines', exist_ok=True)\n",
    "baseline_path = './data/baselines/time_baseline.json'\n",
    "\n",
    "with open(baseline_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(baseline_time_metrics, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSaved time baseline metrics to: {baseline_path}\")\n",
    "\n",
    "# In ra summary\n",
    "print(f\"\\nTIME BASELINE SUMMARY:\")\n",
    "print(f\"   • Peak upload hour: {baseline_time_metrics['statistics']['most_active_hour']}:00\")\n",
    "print(f\"   • Peak upload day: {baseline_time_metrics['statistics']['most_active_day']}\")\n",
    "print(f\"   • Avg videos/hour: {baseline_time_metrics['statistics']['avg_videos_per_hour']:.0f}\")\n",
    "print(f\"   • Avg days to trending: {baseline_time_metrics['time_to_trend']['avg_days']:.1f}\")\n",
    "print(f\"   • Same-day trending: {baseline_time_metrics['time_to_trend']['same_day_percentage']:.1f}%\")\n",
    "\n",
    "print(f\"\\nTOP 3 PEAK HOURS:\")\n",
    "for hour in baseline_time_metrics['hourly_distribution']['peak_hours']:\n",
    "    count = baseline_time_metrics['hourly_distribution']['video_count_by_hour'][hour]\n",
    "    print(f\"   • {hour}:00 - {count:,} videos\")\n",
    "\n",
    "print(f\"\\nTOP 3 PEAK DAYS:\")\n",
    "for day in baseline_time_metrics['daily_distribution']['peak_days']:\n",
    "    count = baseline_time_metrics['daily_distribution']['video_count_by_day'][day]\n",
    "    print(f\"   • {day} - {count:,} videos\")\n",
    "\n",
    "print(f\"\\nUSAGE:\")\n",
    "print(f\"   This baseline will be used to detect:\")\n",
    "print(f\"   • Unusual upload time patterns\")\n",
    "print(f\"   • Day-of-week trending shifts\")\n",
    "print(f\"   • Abnormal time-to-trending\")\n",
    "\n",
    "print(\"Time analysis baseline export completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c43df9-cadd-4ba5-bb45-7a16f24a1fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
