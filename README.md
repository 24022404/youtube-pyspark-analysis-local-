Xem phÃ¢n cÃ´ng á»Ÿ Ä‘Ã¢y:  
https://docs.google.com/document/d/1nSEQl-qYVe-5RHFcNlCl-bvaru_Kta8JkdfGqhvIILg/edit?hl=vi&tab=t.0  

BÃ¡o cÃ¡o Latex á»Ÿ Ä‘Ã¢y:
https://www.overleaf.com/3531892396cjspnhknhykc#a6aceb  

# ğŸ“Š YouTube Real-time Analytics System

Há»‡ thá»‘ng phÃ¢n tÃ­ch YouTube trending videos theo thá»i gian thá»±c sá»­ dá»¥ng **Kafka + PySpark + MongoDB + Flask + Chart.js**

## ğŸ¯ TÃ­nh nÄƒng

âœ… **Real-time Streaming**: Fetch YouTube API â†’ Kafka â†’ Spark Streaming â†’ MongoDB  
âœ… **PhÃ¢n tÃ­ch Ä‘a chiá»u**: Category, Time Patterns, Engagement Metrics  
âœ… **Dá»± Ä‘oÃ¡n AI**: Random Forest + Prophet dá»± Ä‘oÃ¡n trending videos ngÃ y mai  
âœ… **Dashboard Live**: WebSocket real-time updates vá»›i Chart.js  
âœ… **Scalable Architecture**: Docker Compose orchestration  

## ğŸ—ï¸ Kiáº¿n trÃºc

```
YouTube API â†’ Kafka Producer â†’ Kafka Broker
                                    â†“
                            PySpark Streaming
                            (Preprocessing + Analysis + Prediction)
                                    â†“
                                MongoDB
                                    â†“
                            Flask Backend (WebSocket)
                                    â†“
                            Frontend Dashboard (Chart.js)
```

## ğŸ“‚ Cáº¥u trÃºc Project

```
youtube-realtime-analytics/
â”œâ”€â”€ docker-compose.yml          # Orchestrate toÃ n bá»™ services
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ data/
â”‚   â””â”€â”€ baselines/              # Baseline data tá»« file 01-04
â”œâ”€â”€ notebooks/                  # CÃ¡c file notebook gá»‘c (01-05)
â”œâ”€â”€ src/                        # Source code chÃ­nh
â”‚   â”œâ”€â”€ config.py              # Configuration module
â”‚   â”œâ”€â”€ preprocessing.py       # Data preprocessing (tá»« file 01)
â”‚   â”œâ”€â”€ analysis.py            # Analysis functions (tá»« file 02-04)
â”‚   â”œâ”€â”€ kafka_producer.py      # YouTube API â†’ Kafka (tá»« file 05)
â”‚   â”œâ”€â”€ spark_streaming.py     # Spark Structured Streaming
â”‚   â””â”€â”€ prediction_model.py    # ML models (Random Forest + Prophet)
â””â”€â”€ dashboard/
    â”œâ”€â”€ backend/
    â”‚   â””â”€â”€ app.py             # Flask + WebSocket backend
    â””â”€â”€ frontend/
        â”œâ”€â”€ index.html         # Dashboard UI
        â”œâ”€â”€ styles.css         # Styling
        â””â”€â”€ charts.js          # Chart.js logic
```

## ğŸš€ CÃ¡ch cháº¡y

### BÆ°á»›c 1: Chuáº©n bá»‹

```bash
# Clone hoáº·c táº¡o project directory
cd youtube-realtime-analytics

# Táº¡o .env file vÃ  Ä‘iá»n YouTube API Key
cp .env.example .env
# Sá»­a YOUTUBE_API_KEY trong .env
```

### BÆ°á»›c 2: Start táº¥t cáº£ services

```bash
# Start toÃ n bá»™ há»‡ thá»‘ng
docker-compose up -d

# Check logs
docker-compose logs -f
```

### BÆ°á»›c 3: Truy cáº­p Dashboard

Má»Ÿ trÃ¬nh duyá»‡t: **http://localhost**

## ğŸ“‹ Services

| Service | Port | MÃ´ táº£ |
|---------|------|-------|
| Zookeeper | 2181 | Kafka coordination |
| Kafka | 9092, 9093 | Message broker |
| MongoDB | 27017 | Database (admin/admin123) |
| Spark Master | 8080 | Spark Web UI |
| Spark Worker | 8081 | Worker Web UI |
| Flask Backend | 5000 | REST API + WebSocket |
| Nginx Frontend | 80 | Dashboard |

## ğŸ”§ Cáº¥u hÃ¬nh

### YouTube API Key

1. VÃ o [Google Cloud Console](https://console.cloud.google.com/)
2. Táº¡o project má»›i
3. Enable YouTube Data API v3
4. Táº¡o API Key
5. Copy vÃ o `.env`:

```bash
YOUTUBE_API_KEY=your_api_key_here
```

### MongoDB

Default credentials:
- Username: `admin`
- Password: `admin123`
- Database: `youtube_analytics`

### Kafka Topics

- `youtube-trending`: Raw trending videos
- `analytics-results`: Processed analytics

## ğŸ“Š Collections trong MongoDB

1. **trending_videos**: Raw trending videos vá»›i features
2. **analytics_snapshots**: Windowed analytics (1-minute tumbling)
3. **predictions**: Dá»± Ä‘oÃ¡n videos trending ngÃ y mai

## ğŸ¤– Machine Learning Models

### Random Forest Classifier
- **Target**: `will_trend_tomorrow` (0/1)
- **Features**: 10 features (view_velocity, engagement_rate, etc.)
- **Metrics**: AUC, Accuracy

### Random Forest Regressor
- **Target**: `predicted_views_24h`
- **Metrics**: RMSE, RÂ²

### Prophet (Optional)
- Time series forecasting cho view patterns

## ğŸ“ˆ Dashboard Features

1. **Header Stats**: Total videos, Recent videos, Avg engagement
2. **Category Distribution**: Pie chart
3. **Time Patterns**: Bar chart (hourly uploads)
4. **Engagement Rate**: Line chart (real-time updates)
5. **Top Trending**: Top 10 videos
6. **Predictions**: Tomorrow's potential trending videos
7. **Real-time Feed**: Last 5 minutes activity

## ğŸ§ª Testing

### Test Kafka Producer

```bash
docker exec -it kafka-producer python kafka_producer.py --mode test
```

### Test Spark Streaming

```bash
docker exec -it spark-streaming python spark_streaming.py --test-mongo
```

### Test Backend API

```bash
curl http://localhost:5000/api/stats
```

## ğŸ› ï¸ Development

### Run producer locally

```bash
cd src
pip install -r requirements-producer.txt
python kafka_producer.py --mode once
```

### Train models locally

```bash
cd src
pip install -r requirements-streaming.txt
python prediction_model.py --mode train
```

## ğŸ“ Logs

```bash
# View all logs
docker-compose logs -f

# View specific service
docker-compose logs -f kafka-producer
docker-compose logs -f spark-streaming
docker-compose logs -f dashboard-backend
```

## ğŸ› Troubleshooting

### Kafka khÃ´ng connect Ä‘Æ°á»£c?

```bash
# Restart Kafka
docker-compose restart kafka zookeeper
```

### MongoDB khÃ´ng connect Ä‘Æ°á»£c?

```bash
# Check MongoDB logs
docker-compose logs mongodb

# Restart MongoDB
docker-compose restart mongodb
```

### Dashboard khÃ´ng hiá»‡n data?

1. Check backend logs: `docker-compose logs dashboard-backend`
2. Check MongoDB cÃ³ data: 
   ```bash
   docker exec -it mongodb mongosh -u admin -p admin123
   use youtube_analytics
   db.trending_videos.count()
   ```

### Spark job khÃ´ng cháº¡y?

```bash
# Check Spark logs
docker-compose logs spark-streaming

# Restart Spark
docker-compose restart spark-master spark-worker-1 spark-streaming
```

## ğŸ”¥ Stop Services

```bash
# Stop all
docker-compose down

# Stop and remove volumes
docker-compose down -v
```

## ğŸ“š Tham kháº£o

- [Kafka Documentation](https://kafka.apache.org/documentation/)
- [PySpark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [YouTube Data API](https://developers.google.com/youtube/v3)
- [Chart.js](https://www.chartjs.org/)
- [Flask-SocketIO](https://flask-socketio.readthedocs.io/)

## ğŸ‘¥ Credits

ÄÆ°á»£c phÃ¡t triá»ƒn dá»±a trÃªn cÃ¡c file 01-05 (preprocessing, category analysis, time analysis, interaction analysis, real-time monitoring).

**TÃ¡i sá»­ dá»¥ng 100% logic tá»« cÃ¡c file gá»‘c, nÃ¢ng cáº¥p lÃªn kiáº¿n trÃºc real-time streaming!**

## ğŸ“„ License

MIT License