{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# INTEGRATED REAL-TIME MONITORING SYSTEM\n",
    "# ========================================\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['JAVA_HOME'] = 'C:\\\\Java\\\\jdk-1.8'\n",
    "os.environ['HADOOP_HOME'] = os.environ.get('JAVA_HOME')\n",
    "os.environ['PATH'] = f\"{os.environ['JAVA_HOME']}\\\\bin;{os.environ.get('PATH', '')}\"\n",
    "\n",
    "print(f\"‚úÖ JAVA_HOME: {os.environ['JAVA_HOME']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# INSTALL PACKAGES\n",
    "# ========================================\n",
    "!pip install google-api-python-client pandas matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# IMPORT LIBRARIES\n",
    "# ========================================\n",
    "from googleapiclient.discovery import build\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_baselines",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# LOAD ALL BASELINES\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä LOADING ALL BASELINE METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baselines = {}\n",
    "\n",
    "# Load Category Baseline\n",
    "try:\n",
    "    with open('./data/baselines/category_baseline.json', 'r', encoding='utf-8') as f:\n",
    "        baselines['category'] = json.load(f)\n",
    "    print(\"‚úÖ Category baseline loaded\")\n",
    "    print(f\"   ‚Ä¢ Created: {baselines['category']['timestamp']}\")\n",
    "    print(f\"   ‚Ä¢ Videos: {baselines['category']['statistics']['total_videos']:,}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Category baseline not found! Run 02_category_analysis.ipynb\")\n",
    "    baselines['category'] = None\n",
    "\n",
    "# Load Time Baseline\n",
    "try:\n",
    "    with open('./data/baselines/time_baseline.json', 'r', encoding='utf-8') as f:\n",
    "        baselines['time'] = json.load(f)\n",
    "    print(\"‚úÖ Time baseline loaded\")\n",
    "    print(f\"   ‚Ä¢ Peak hour: {baselines['time']['statistics']['most_active_hour']}:00\")\n",
    "    print(f\"   ‚Ä¢ Peak day: {baselines['time']['statistics']['most_active_day']}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Time baseline not found! Run 03_time_analysis.ipynb\")\n",
    "    baselines['time'] = None\n",
    "\n",
    "# Load Interaction Baseline\n",
    "try:\n",
    "    with open('./data/baselines/interaction_baseline.json', 'r', encoding='utf-8') as f:\n",
    "        baselines['interaction'] = json.load(f)\n",
    "    print(\"‚úÖ Interaction baseline loaded\")\n",
    "    print(f\"   ‚Ä¢ Avg views: {baselines['interaction']['statistics']['avg_views_per_video']:,}\")\n",
    "    print(f\"   ‚Ä¢ Viral threshold: {baselines['interaction']['thresholds']['viral_view_threshold']:,}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Interaction baseline not found! Run 04_interaction_analysis.ipynb\")\n",
    "    baselines['interaction'] = None\n",
    "\n",
    "loaded_count = sum(1 for v in baselines.values() if v is not None)\n",
    "print(f\"\\nüìã Loaded {loaded_count}/3 baselines\")\n",
    "\n",
    "if loaded_count == 0:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: No baselines loaded! Cannot proceed.\")\n",
    "    print(\"   Please run files 02, 03, 04 first to generate baselines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# YOUTUBE API SETUP\n",
    "# ========================================\n",
    "\n",
    "# ‚ö†Ô∏è THAY API KEY C·ª¶A B·∫†N ·ªû ƒê√ÇY!\n",
    "API_KEY = 'AIzaSyBHZ-BVjZUVWMxhJfJ3k85PdQh12Hyf70k'  # ‚Üê THAY ƒê·ªîI!\n",
    "\n",
    "try:\n",
    "    youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "    print(\"‚úÖ YouTube API initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå API initialization failed: {e}\")\n",
    "    youtube = None\n",
    "\n",
    "# Category mapping\n",
    "CATEGORY_MAP = {\n",
    "    '1': 'Film & Animation', '2': 'Autos & Vehicles', '10': 'Music',\n",
    "    '15': 'Pets & Animals', '17': 'Sports', '19': 'Travel & Events',\n",
    "    '20': 'Gaming', '22': 'People & Blogs', '23': 'Comedy',\n",
    "    '24': 'Entertainment', '25': 'News & Politics', '26': 'Howto & Style',\n",
    "    '27': 'Education', '28': 'Science & Technology', '29': 'Nonprofits & Activism'\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Category mapping loaded ({len(CATEGORY_MAP)} categories)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fetch_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# FETCH CURRENT TRENDING FUNCTION\n",
    "# ========================================\n",
    "\n",
    "def get_current_trending(region_code='US', max_results=50):\n",
    "    \"\"\"\n",
    "    L·∫•y danh s√°ch trending videos HI·ªÜN T·∫†I\n",
    "    \"\"\"\n",
    "    if youtube is None:\n",
    "        print(\"‚ùå YouTube API not initialized\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        request = youtube.videos().list(\n",
    "            part='snippet,statistics',\n",
    "            chart='mostPopular',\n",
    "            regionCode=region_code,\n",
    "            maxResults=max_results\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        videos = []\n",
    "        for item in response.get('items', []):\n",
    "            snippet = item['snippet']\n",
    "            stats = item['statistics']\n",
    "            published = datetime.strptime(snippet['publishedAt'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "            \n",
    "            videos.append({\n",
    "                'video_id': item['id'],\n",
    "                'title': snippet.get('title', ''),\n",
    "                'channel': snippet.get('channelTitle', ''),\n",
    "                'category_id': snippet.get('categoryId', ''),\n",
    "                'category_name': CATEGORY_MAP.get(snippet.get('categoryId', ''), 'Unknown'),\n",
    "                'views': int(stats.get('viewCount', 0)),\n",
    "                'likes': int(stats.get('likeCount', 0)),\n",
    "                'comments': int(stats.get('commentCount', 0)),\n",
    "                'published_at': published,\n",
    "                'publish_hour': published.hour,\n",
    "                'publish_day': published.strftime('%a'),\n",
    "                'fetched_at': datetime.now()\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(videos)\n",
    "        \n",
    "        # Calculate engagement\n",
    "        if not df.empty:\n",
    "            df['like_rate'] = (df['likes'] / df['views'] * 100)\n",
    "            df['comment_rate'] = (df['comments'] / df['views'] * 100)\n",
    "            df['engagement_rate'] = ((df['likes'] + df['comments']) / df['views'] * 100)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"‚úÖ Function defined: get_current_trending()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_category",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CATEGORY COMPARISON FUNCTION\n",
    "# ========================================\n",
    "\n",
    "def compare_category(current_df, baseline):\n",
    "    \"\"\"\n",
    "    So s√°nh category distribution v·ªõi baseline\n",
    "    \"\"\"\n",
    "    if current_df.empty or baseline is None:\n",
    "        return None, []\n",
    "    \n",
    "    # Current distribution\n",
    "    current_dist = current_df['category_name'].value_counts()\n",
    "    current_pct = (current_dist / len(current_df) * 100).to_dict()\n",
    "    \n",
    "    # Baseline distribution\n",
    "    baseline_pct = baseline['category_distribution']['by_percentage']\n",
    "    \n",
    "    comparison = []\n",
    "    anomalies = []\n",
    "    \n",
    "    for category in baseline_pct.keys():\n",
    "        base_val = baseline_pct[category]\n",
    "        curr_val = current_pct.get(category, 0)\n",
    "        change = curr_val - base_val\n",
    "        change_ratio = (change / base_val * 100) if base_val > 0 else 0\n",
    "        \n",
    "        comparison.append({\n",
    "            'category': category,\n",
    "            'baseline_%': base_val,\n",
    "            'current_%': curr_val,\n",
    "            'change_%': change,\n",
    "            'change_ratio': change_ratio\n",
    "        })\n",
    "        \n",
    "        # Detect anomalies (>20% change)\n",
    "        if abs(change_ratio) > 20:\n",
    "            anomalies.append({\n",
    "                'type': 'CATEGORY',\n",
    "                'category': category,\n",
    "                'direction': 'üìà SURGE' if change_ratio > 0 else 'üìâ DECLINE',\n",
    "                'change_ratio': change_ratio,\n",
    "                'current': curr_val,\n",
    "                'baseline': base_val\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(comparison).sort_values('change_ratio', ascending=False), anomalies\n",
    "\n",
    "print(\"‚úÖ Function defined: compare_category()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_time",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# TIME PATTERN COMPARISON FUNCTION\n",
    "# ========================================\n",
    "\n",
    "def compare_time_patterns(current_df, baseline):\n",
    "    \"\"\"\n",
    "    So s√°nh time patterns v·ªõi baseline\n",
    "    \"\"\"\n",
    "    if current_df.empty or baseline is None:\n",
    "        return None, []\n",
    "    \n",
    "    anomalies = []\n",
    "    \n",
    "    # Hourly comparison\n",
    "    current_hourly = current_df['publish_hour'].value_counts().to_dict()\n",
    "    baseline_hourly = baseline['hourly_distribution']['video_count_by_hour']\n",
    "    avg_per_hour = baseline['statistics']['avg_videos_per_hour']\n",
    "    \n",
    "    for hour in range(24):\n",
    "        curr = current_hourly.get(hour, 0)\n",
    "        base = baseline_hourly.get(str(hour), avg_per_hour)\n",
    "        \n",
    "        if base > 0:\n",
    "            change_ratio = ((curr - base) / base * 100)\n",
    "            \n",
    "            # Anomaly if >50% change\n",
    "            if abs(change_ratio) > 50:\n",
    "                anomalies.append({\n",
    "                    'type': 'TIME_HOUR',\n",
    "                    'hour': hour,\n",
    "                    'direction': 'üìà SURGE' if change_ratio > 0 else 'üìâ DROP',\n",
    "                    'change_ratio': change_ratio,\n",
    "                    'current': curr,\n",
    "                    'baseline': base\n",
    "                })\n",
    "    \n",
    "    # Day of week comparison\n",
    "    current_daily = current_df['publish_day'].value_counts().to_dict()\n",
    "    baseline_daily = baseline['daily_distribution']['video_count_by_day']\n",
    "    avg_per_day = baseline['statistics']['avg_videos_per_day']\n",
    "    \n",
    "    for day in ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']:\n",
    "        curr = current_daily.get(day, 0)\n",
    "        base = baseline_daily.get(day, avg_per_day)\n",
    "        \n",
    "        if base > 0:\n",
    "            change_ratio = ((curr - base) / base * 100)\n",
    "            \n",
    "            if abs(change_ratio) > 50:\n",
    "                anomalies.append({\n",
    "                    'type': 'TIME_DAY',\n",
    "                    'day': day,\n",
    "                    'direction': 'üìà SURGE' if change_ratio > 0 else 'üìâ DROP',\n",
    "                    'change_ratio': change_ratio,\n",
    "                    'current': curr,\n",
    "                    'baseline': base\n",
    "                })\n",
    "    \n",
    "    return current_hourly, anomalies\n",
    "\n",
    "print(\"‚úÖ Function defined: compare_time_patterns()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ENGAGEMENT COMPARISON FUNCTION\n",
    "# ========================================\n",
    "\n",
    "def compare_engagement(current_df, baseline):\n",
    "    \"\"\"\n",
    "    So s√°nh engagement metrics v·ªõi baseline\n",
    "    \"\"\"\n",
    "    if current_df.empty or baseline is None:\n",
    "        return None, []\n",
    "    \n",
    "    anomalies = []\n",
    "    \n",
    "    # Current stats\n",
    "    curr_avg_views = current_df['views'].mean()\n",
    "    curr_avg_likes = current_df['likes'].mean()\n",
    "    curr_engagement = current_df['engagement_rate'].mean()\n",
    "    \n",
    "    # Baseline stats\n",
    "    base_avg_views = baseline['statistics']['avg_views_per_video']\n",
    "    base_avg_likes = baseline['statistics']['avg_likes_per_video']\n",
    "    base_engagement = baseline['engagement_benchmarks']['avg_engagement_rate']\n",
    "    \n",
    "    # Compare overall engagement\n",
    "    eng_change = ((curr_engagement - base_engagement) / base_engagement * 100)\n",
    "    \n",
    "    if abs(eng_change) > 20:\n",
    "        anomalies.append({\n",
    "            'type': 'ENGAGEMENT_OVERALL',\n",
    "            'direction': 'üìà SURGE' if eng_change > 0 else 'üìâ DECLINE',\n",
    "            'change_ratio': eng_change,\n",
    "            'current': curr_engagement,\n",
    "            'baseline': base_engagement\n",
    "        })\n",
    "    \n",
    "    # Detect viral videos\n",
    "    viral_threshold = baseline['thresholds']['viral_view_threshold']\n",
    "    viral_videos = current_df[current_df['views'] > viral_threshold]\n",
    "    \n",
    "    if len(viral_videos) > 0:\n",
    "        for _, video in viral_videos.iterrows():\n",
    "            anomalies.append({\n",
    "                'type': 'VIRAL_VIDEO',\n",
    "                'direction': 'üî• VIRAL',\n",
    "                'title': video['title'][:50],\n",
    "                'views': int(video['views']),\n",
    "                'threshold': viral_threshold,\n",
    "                'category': video['category_name']\n",
    "            })\n",
    "    \n",
    "    # Detect low engagement\n",
    "    low_threshold = baseline['thresholds']['low_engagement_threshold']\n",
    "    low_engagement = current_df[current_df['engagement_rate'] < low_threshold]\n",
    "    \n",
    "    if len(low_engagement) > 5:  # More than 5 videos\n",
    "        anomalies.append({\n",
    "            'type': 'LOW_ENGAGEMENT',\n",
    "            'direction': '‚ö†Ô∏è WARNING',\n",
    "            'count': len(low_engagement),\n",
    "            'threshold': low_threshold\n",
    "        })\n",
    "    \n",
    "    results = {\n",
    "        'current_avg_views': curr_avg_views,\n",
    "        'baseline_avg_views': base_avg_views,\n",
    "        'current_avg_likes': curr_avg_likes,\n",
    "        'baseline_avg_likes': base_avg_likes,\n",
    "        'current_engagement': curr_engagement,\n",
    "        'baseline_engagement': base_engagement\n",
    "    }\n",
    "    \n",
    "    return results, anomalies\n",
    "\n",
    "print(\"‚úÖ Function defined: compare_engagement()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous_monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CONTINUOUS MONITORING FUNCTION\n",
    "# ========================================\n",
    "\n",
    "def continuous_monitoring(duration_minutes=10, interval_seconds=300):\n",
    "    \"\"\"\n",
    "    Gi√°m s√°t li√™n t·ª•c trong X ph√∫t, c·∫≠p nh·∫≠t m·ªói Y gi√¢y\n",
    "    \n",
    "    Parameters:\n",
    "    - duration_minutes: T·ªïng th·ªùi gian ch·∫°y (m·∫∑c ƒë·ªãnh 10 ph√∫t)\n",
    "    - interval_seconds: Kho·∫£ng c√°ch gi·ªØa c√°c l·∫ßn c·∫≠p nh·∫≠t (m·∫∑c ƒë·ªãnh 300s = 5 ph√∫t)\n",
    "    \"\"\"\n",
    "    # Check baselines\n",
    "    if not any(baselines.values()):\n",
    "        print(\"‚ùå No baselines available! Cannot monitor.\")\n",
    "        return None\n",
    "    \n",
    "    if youtube is None:\n",
    "        print(\"‚ùå YouTube API not initialized!\")\n",
    "        return None\n",
    "    \n",
    "    end_time = datetime.now() + timedelta(minutes=duration_minutes)\n",
    "    iteration = 0\n",
    "    history = []\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"üöÄ STARTING CONTINUOUS REAL-TIME MONITORING\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Duration: {duration_minutes} minutes\")\n",
    "    print(f\"Update interval: {interval_seconds} seconds ({interval_seconds//60} minutes)\")\n",
    "    print(f\"End time: {end_time.strftime('%H:%M:%S')}\")\n",
    "    print(f\"Monitoring: Category{'‚úì' if baselines['category'] else '‚úó'} | \"\n",
    "          f\"Time{'‚úì' if baselines['time'] else '‚úó'} | \"\n",
    "          f\"Engagement{'‚úì' if baselines['interaction'] else '‚úó'}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        while datetime.now() < end_time:\n",
    "            iteration += 1\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print(\"=\"*80)\n",
    "            print(f\"‚è∞ ITERATION #{iteration} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            # Fetch current data\n",
    "            print(\"\\n‚è≥ Fetching current trending videos...\")\n",
    "            current_df = get_current_trending()\n",
    "            \n",
    "            if current_df.empty:\n",
    "                print(\"‚ùå Failed to fetch data\")\n",
    "                time.sleep(interval_seconds)\n",
    "                continue\n",
    "            \n",
    "            print(f\"‚úÖ Fetched {len(current_df)} trending videos\")\n",
    "            \n",
    "            # Collect all anomalies\n",
    "            all_anomalies = []\n",
    "            \n",
    "            # =====================================\n",
    "            # 1. CATEGORY ANALYSIS\n",
    "            # =====================================\n",
    "            if baselines['category']:\n",
    "                print(f\"\\n{'‚îÄ'*80}\")\n",
    "                print(\"üìÇ CATEGORY ANALYSIS\")\n",
    "                print(f\"{'‚îÄ'*80}\")\n",
    "                \n",
    "                cat_comparison, cat_anomalies = compare_category(current_df, baselines['category'])\n",
    "                \n",
    "                if cat_comparison is not None:\n",
    "                    # Top 3 categories NOW\n",
    "                    top3_now = current_df['category_name'].value_counts().head(3)\n",
    "                    print(\"\\nüî• TOP 3 CATEGORIES NOW:\")\n",
    "                    for cat, count in top3_now.items():\n",
    "                        pct = (count / len(current_df) * 100)\n",
    "                        base_pct = baselines['category']['category_distribution']['by_percentage'].get(cat, 0)\n",
    "                        change = pct - base_pct\n",
    "                        arrow = '‚ÜóÔ∏è' if change > 0 else '‚ÜòÔ∏è' if change < 0 else '‚Üí'\n",
    "                        print(f\"   {arrow} {cat}: {pct:.1f}% (baseline: {base_pct:.1f}%, {change:+.1f}%)\")\n",
    "                    \n",
    "                    if cat_anomalies:\n",
    "                        all_anomalies.extend(cat_anomalies)\n",
    "            \n",
    "            # =====================================\n",
    "            # 2. TIME PATTERN ANALYSIS\n",
    "            # =====================================\n",
    "            if baselines['time']:\n",
    "                print(f\"\\n{'‚îÄ'*80}\")\n",
    "                print(\"üïê TIME PATTERN ANALYSIS\")\n",
    "                print(f\"{'‚îÄ'*80}\")\n",
    "                \n",
    "                time_data, time_anomalies = compare_time_patterns(current_df, baselines['time'])\n",
    "                \n",
    "                # Show current hour distribution\n",
    "                if time_data:\n",
    "                    peak_hour = max(time_data, key=time_data.get)\n",
    "                    print(f\"\\nüïê Peak upload hour NOW: {peak_hour}:00 ({time_data[peak_hour]} videos)\")\n",
    "                    print(f\"   Baseline peak: {baselines['time']['statistics']['most_active_hour']}:00\")\n",
    "                    \n",
    "                    if time_anomalies:\n",
    "                        all_anomalies.extend(time_anomalies)\n",
    "            \n",
    "            # =====================================\n",
    "            # 3. ENGAGEMENT ANALYSIS\n",
    "            # =====================================\n",
    "            if baselines['interaction']:\n",
    "                print(f\"\\n{'‚îÄ'*80}\")\n",
    "                print(\"üíù ENGAGEMENT ANALYSIS\")\n",
    "                print(f\"{'‚îÄ'*80}\")\n",
    "                \n",
    "                eng_data, eng_anomalies = compare_engagement(current_df, baselines['interaction'])\n",
    "                \n",
    "                if eng_data:\n",
    "                    print(f\"\\nüìä Current Metrics:\")\n",
    "                    print(f\"   Views: {eng_data['current_avg_views']:,.0f} \"\n",
    "                          f\"(baseline: {eng_data['baseline_avg_views']:,.0f})\")\n",
    "                    print(f\"   Likes: {eng_data['current_avg_likes']:,.0f} \"\n",
    "                          f\"(baseline: {eng_data['baseline_avg_likes']:,.0f})\")\n",
    "                    print(f\"   Engagement: {eng_data['current_engagement']:.2f}% \"\n",
    "                          f\"(baseline: {eng_data['baseline_engagement']:.2f}%)\")\n",
    "                    \n",
    "                    if eng_anomalies:\n",
    "                        all_anomalies.extend(eng_anomalies)\n",
    "            \n",
    "            # =====================================\n",
    "            # ALERT SUMMARY\n",
    "            # =====================================\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            if all_anomalies:\n",
    "                print(f\"üö® {len(all_anomalies)} ANOMALIES DETECTED!\")\n",
    "                print(f\"{'='*80}\")\n",
    "                \n",
    "                for i, anomaly in enumerate(all_anomalies, 1):\n",
    "                    print(f\"\\n#{i}. {anomaly['type']} - {anomaly['direction']}\")\n",
    "                    \n",
    "                    if anomaly['type'] == 'CATEGORY':\n",
    "                        print(f\"   Category: {anomaly['category']}\")\n",
    "                        print(f\"   Current: {anomaly['current']:.1f}% | Baseline: {anomaly['baseline']:.1f}%\")\n",
    "                        print(f\"   Change: {anomaly['change_ratio']:+.1f}%\")\n",
    "                    \n",
    "                    elif anomaly['type'] == 'TIME_HOUR':\n",
    "                        print(f\"   Hour: {anomaly['hour']}:00\")\n",
    "                        print(f\"   Current: {anomaly['current']} videos | Baseline: {anomaly['baseline']:.0f}\")\n",
    "                        print(f\"   Change: {anomaly['change_ratio']:+.0f}%\")\n",
    "                    \n",
    "                    elif anomaly['type'] == 'TIME_DAY':\n",
    "                        print(f\"   Day: {anomaly['day']}\")\n",
    "                        print(f\"   Current: {anomaly['current']} videos | Baseline: {anomaly['baseline']:.0f}\")\n",
    "                        print(f\"   Change: {anomaly['change_ratio']:+.0f}%\")\n",
    "                    \n",
    "                    elif anomaly['type'] == 'VIRAL_VIDEO':\n",
    "                        print(f\"   Title: {anomaly['title']}...\")\n",
    "                        print(f\"   Views: {anomaly['views']:,} (threshold: {anomaly['threshold']:,})\")\n",
    "                        print(f\"   Category: {anomaly['category']}\")\n",
    "                    \n",
    "                    elif anomaly['type'] == 'ENGAGEMENT_OVERALL':\n",
    "                        print(f\"   Current: {anomaly['current']:.2f}% | Baseline: {anomaly['baseline']:.2f}%\")\n",
    "                        print(f\"   Change: {anomaly['change_ratio']:+.1f}%\")\n",
    "                    \n",
    "                    elif anomaly['type'] == 'LOW_ENGAGEMENT':\n",
    "                        print(f\"   {anomaly['count']} videos with engagement < {anomaly['threshold']:.2f}%\")\n",
    "            else:\n",
    "                print(\"‚úÖ NO SIGNIFICANT ANOMALIES\")\n",
    "                print(f\"{'='*80}\")\n",
    "            \n",
    "            # Top 3 trending NOW\n",
    "            print(f\"\\nüî• TOP 3 TRENDING NOW:\")\n",
    "            for i, row in current_df.head(3).iterrows():\n",
    "                print(f\"   {i+1}. {row['title'][:60]}...\")\n",
    "                print(f\"      {row['views']:,} views | {row['category_name']}\")\n",
    "            \n",
    "            # Save to history\n",
    "            history.append({\n",
    "                'timestamp': datetime.now(),\n",
    "                'iteration': iteration,\n",
    "                'videos_count': len(current_df),\n",
    "                'anomalies_count': len(all_anomalies),\n",
    "                'top_category': current_df['category_name'].value_counts().index[0],\n",
    "                'avg_engagement': current_df['engagement_rate'].mean()\n",
    "            })\n",
    "            \n",
    "            # Wait for next iteration\n",
    "            remaining = (end_time - datetime.now()).seconds\n",
    "            if remaining > 0:\n",
    "                print(f\"\\n‚è≥ Next update in {interval_seconds} seconds...\")\n",
    "                print(f\"   Time remaining: {remaining // 60} min {remaining % 60} sec\")\n",
    "                time.sleep(min(interval_seconds, remaining))\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è Monitoring stopped by user\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ MONITORING COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total iterations: {iteration}\")\n",
    "    print(f\"Duration: {duration_minutes} minutes\")\n",
    "    \n",
    "    if history:\n",
    "        history_df = pd.DataFrame(history)\n",
    "        print(f\"\\nüìä SUMMARY:\")\n",
    "        print(f\"   Total anomalies detected: {history_df['anomalies_count'].sum()}\")\n",
    "        print(f\"   Avg anomalies per iteration: {history_df['anomalies_count'].mean():.1f}\")\n",
    "        print(f\"   Most common top category: {history_df['top_category'].mode()[0]}\")\n",
    "        \n",
    "        return history_df\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"‚úÖ Function defined: continuous_monitoring()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# RUN CONTINUOUS MONITORING\n",
    "# ========================================\n",
    "\n",
    "# ‚ö†Ô∏è ƒêi·ªÅu ch·ªânh tham s·ªë ·ªü ƒë√¢y:\n",
    "# - duration_minutes: T·ªïng th·ªùi gian ch·∫°y (m·∫∑c ƒë·ªãnh 10 ph√∫t)\n",
    "# - interval_seconds: Kho·∫£ng c√°ch gi·ªØa c√°c l·∫ßn c·∫≠p nh·∫≠t (m·∫∑c ƒë·ªãnh 300s = 5 ph√∫t)\n",
    "\n",
    "# Ch·∫°y monitoring trong 10 ph√∫t, c·∫≠p nh·∫≠t m·ªói 5 ph√∫t\n",
    "history_df = continuous_monitoring(duration_minutes=10, interval_seconds=300)\n",
    "\n",
    "# N·∫øu mu·ªën test nhanh: 2 ph√∫t, c·∫≠p nh·∫≠t m·ªói 1 ph√∫t\n",
    "# history_df = continuous_monitoring(duration_minutes=2, interval_seconds=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# VISUALIZE MONITORING HISTORY\n",
    "# ========================================\n",
    "\n",
    "if history_df is not None and len(history_df) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä MONITORING HISTORY VISUALIZATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # Plot 1: Anomalies over time\n",
    "    axes[0, 0].plot(history_df['iteration'], history_df['anomalies_count'], \n",
    "                    marker='o', linewidth=2, markersize=8)\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Number of Anomalies')\n",
    "    axes[0, 0].set_title('üö® Anomalies Detected Over Time')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Top category distribution\n",
    "    top_cat_counts = history_df['top_category'].value_counts()\n",
    "    axes[0, 1].bar(range(len(top_cat_counts)), top_cat_counts.values)\n",
    "    axes[0, 1].set_xticks(range(len(top_cat_counts)))\n",
    "    axes[0, 1].set_xticklabels(top_cat_counts.index, rotation=45, ha='right')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('üèÜ Most Frequent Top Category')\n",
    "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Average engagement over time\n",
    "    axes[1, 0].plot(history_df['iteration'], history_df['avg_engagement'], \n",
    "                    marker='s', linewidth=2, markersize=8, color='green')\n",
    "    axes[1, 0].set_xlabel('Iteration')\n",
    "    axes[1, 0].set_ylabel('Avg Engagement Rate (%)')\n",
    "    axes[1, 0].set_title('üíù Average Engagement Over Time')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Summary table\n",
    "    axes[1, 1].axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "    MONITORING SUMMARY\n",
    "    {'='*40}\n",
    "    \n",
    "    Total Iterations: {len(history_df)}\n",
    "    \n",
    "    Total Anomalies: {history_df['anomalies_count'].sum()}\n",
    "    Avg per Iteration: {history_df['anomalies_count'].mean():.1f}\n",
    "    Max in Single Iteration: {history_df['anomalies_count'].max()}\n",
    "    \n",
    "    Most Common Top Category:\n",
    "    {history_df['top_category'].mode()[0]}\n",
    "    \n",
    "    Avg Engagement Rate:\n",
    "    {history_df['avg_engagement'].mean():.2f}%\n",
    "    \n",
    "    Start Time: {history_df['timestamp'].min().strftime('%H:%M:%S')}\n",
    "    End Time: {history_df['timestamp'].max().strftime('%H:%M:%S')}\n",
    "    \"\"\"\n",
    "    axes[1, 1].text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "                    verticalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show detailed history\n",
    "    print(\"\\nüìã Detailed History:\")\n",
    "    display(history_df)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No history data to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SAVE MONITORING HISTORY (OPTIONAL)\n",
    "# ========================================\n",
    "\n",
    "if history_df is not None:\n",
    "    import os\n",
    "    \n",
    "    # Create logs directory\n",
    "    os.makedirs('./data/logs', exist_ok=True)\n",
    "    \n",
    "    # Save to CSV with timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'./data/logs/monitoring_history_{timestamp}.csv'\n",
    "    history_df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ History saved to: {filename}\")\n",
    "    print(f\"   Rows: {len(history_df)}\")\n",
    "    print(f\"   Columns: {', '.join(history_df.columns)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No history to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# FINAL SUMMARY\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ INTEGRATED REAL-TIME MONITORING COMPLETED!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ What was monitored:\")\n",
    "if baselines['category']:\n",
    "    print(\"   ‚úì Category distribution shifts\")\n",
    "if baselines['time']:\n",
    "    print(\"   ‚úì Time pattern anomalies\")\n",
    "if baselines['interaction']:\n",
    "    print(\"   ‚úì Engagement metrics & viral detection\")\n",
    "\n",
    "print(\"\\nüìä Capabilities demonstrated:\")\n",
    "print(\"   ‚Ä¢ Real-time data fetching from YouTube API\")\n",
    "print(\"   ‚Ä¢ Multi-dimensional baseline comparison\")\n",
    "print(\"   ‚Ä¢ Automatic anomaly detection\")\n",
    "print(\"   ‚Ä¢ Continuous monitoring with auto-refresh\")\n",
    "print(\"   ‚Ä¢ Alert system for significant changes\")\n",
    "\n",
    "print(\"\\nüí° This system can:\")\n",
    "print(\"   ‚Ä¢ Detect trending category shifts in real-time\")\n",
    "print(\"   ‚Ä¢ Identify unusual upload time patterns\")\n",
    "print(\"   ‚Ä¢ Spot viral videos as they emerge\")\n",
    "print(\"   ‚Ä¢ Alert on engagement anomalies\")\n",
    "print(\"   ‚Ä¢ Track changes over continuous monitoring periods\")\n",
    "\n",
    "print(\"\\nüöÄ Next steps for production:\")\n",
    "print(\"   ‚Ä¢ Deploy on cloud server (AWS/GCP/Azure)\")\n",
    "print(\"   ‚Ä¢ Set up automated scheduling (cron jobs)\")\n",
    "print(\"   ‚Ä¢ Integrate with notification system (email/Slack)\")\n",
    "print(\"   ‚Ä¢ Add database for long-term history storage\")\n",
    "print(\"   ‚Ä¢ Build interactive web dashboard\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
