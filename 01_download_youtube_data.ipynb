{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Data Crawler\n",
    "Crawl trending videos v√† l∆∞u v√†o CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.186.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-python-client) (0.31.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-python-client) (2.42.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-python-client) (0.2.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-python-client) (2.28.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-python-client) (4.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.71.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ducmi\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# C√†i ƒë·∫∑t th∆∞ vi·ªán (ch·ªâ ch·∫°y l·∫ßn ƒë·∫ßu)\n",
    "!pip install google-api-python-client pandas --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THAY YOUR_API_KEY_HERE b·∫±ng API key th·∫≠t c·ªßa b·∫°n\n",
    "API_KEY = 'AIzaSyBHZ-BVjZUVWMxhJfJ3k85PdQh12Hyf70k'\n",
    "CSV_FILE = './data/raw_data.csv'  # K·∫øt h·ª£p v·ªõi file Kaggle\n",
    "MAX_RESULTS = 50  # S·ªë video mu·ªën crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trending_videos(api_key, region_code='US', max_results=50):\n",
    "    \"\"\"L·∫•y danh s√°ch video trending\"\"\"\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    \n",
    "    # L·∫•y video trending\n",
    "    request = youtube.videos().list(\n",
    "        part='snippet,statistics,contentDetails',\n",
    "        chart='mostPopular',\n",
    "        regionCode=region_code,\n",
    "        maxResults=max_results\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    videos_data = []\n",
    "    trending_date = datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    \n",
    "    for item in response['items']:\n",
    "        snippet = item['snippet']\n",
    "        stats = item['statistics']\n",
    "        \n",
    "        video_info = {\n",
    "            'video_id': item['id'],\n",
    "            'title': snippet['title'],\n",
    "            'publishedAt': snippet['publishedAt'],\n",
    "            'channelId': snippet['channelId'],\n",
    "            'channelTitle': snippet['channelTitle'],\n",
    "            'categoryId': snippet['categoryId'],\n",
    "            'trending_date': trending_date,\n",
    "            'tags': '|'.join(snippet.get('tags', [])),\n",
    "            'view_count': int(stats.get('viewCount', 0)),\n",
    "            'likes': int(stats.get('likeCount', 0)),\n",
    "            'dislikes': 0,  # YouTube API kh√¥ng c√≤n tr·∫£ v·ªÅ dislike\n",
    "            'comment_count': int(stats.get('commentCount', 0)),\n",
    "            'thumbnail_link': snippet['thumbnails']['default']['url'],\n",
    "            'comments_disabled': 'commentCount' not in stats,\n",
    "            'ratings_disabled': False,\n",
    "            'description': snippet['description']\n",
    "        }\n",
    "        videos_data.append(video_info)\n",
    "    \n",
    "    return videos_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, filename):\n",
    "    \"\"\"L∆∞u ho·∫∑c b·ªï sung data v√†o CSV\"\"\"\n",
    "    df_new = pd.DataFrame(data)\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        # ƒê·ªçc CSV c≈© v√† b·ªï sung\n",
    "        df_old = pd.read_csv(filename)\n",
    "        df_combined = pd.concat([df_old, df_new], ignore_index=True)\n",
    "        # X√≥a tr√πng l·∫∑p theo video_id v√† trending_date\n",
    "        df_combined = df_combined.drop_duplicates(subset=['video_id', 'trending_date'], keep='last')\n",
    "        df_combined.to_csv(filename, index=False)\n",
    "        print(f\"‚úÖ ƒê√£ b·ªï sung {len(df_new)} videos v√†o {filename}\")\n",
    "        print(f\"üìä T·ªïng s·ªë videos: {len(df_combined)}\")\n",
    "    else:\n",
    "        # T·∫°o file m·ªõi\n",
    "        df_new.to_csv(filename, index=False)\n",
    "        print(f\"‚úÖ ƒê√£ t·∫°o file m·ªõi {filename} v·ªõi {len(df_new)} videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu crawl YouTube data...\n",
      "‚úÖ ƒê√£ b·ªï sung 50 videos v√†o ./data/raw_data.csv\n",
      "üìä T·ªïng s·ªë videos: 264767\n",
      "\n",
      "‚úÖ HO√ÄN TH√ÄNH!\n",
      "\n",
      "üì∫ 5 video ƒë·∫ßu ti√™n:\n",
      "                                              title        channelTitle  \\\n",
      "0  BAD OMENS - Left For Good (Official Music Video)            SUMERIAN   \n",
      "1                           Moana | Official Teaser              Disney   \n",
      "2    New LOS TACO BLOCKS + Taco Tuesday Admin Abuse          CaylusBlox   \n",
      "3                        BABYMONSTER - ‚ÄòPSYCHO‚Äô M/V         BABYMONSTER   \n",
      "4            Project Hail Mary | Official Trailer 2  Amazon MGM Studios   \n",
      "\n",
      "   view_count   likes  \n",
      "0      273893   40415  \n",
      "1     4367987   33933  \n",
      "2     1663596   28003  \n",
      "3     7295953  426591  \n",
      "4     3273290   32800  \n"
     ]
    }
   ],
   "source": [
    "# CH·∫†Y CRAWLER\n",
    "print(\"üöÄ B·∫Øt ƒë·∫ßu crawl YouTube data...\")\n",
    "try:\n",
    "    videos = get_trending_videos(API_KEY, region_code='US', max_results=MAX_RESULTS)\n",
    "    save_to_csv(videos, CSV_FILE)\n",
    "    print(\"\\n‚úÖ HO√ÄN TH√ÄNH!\")\n",
    "    \n",
    "    # Hi·ªÉn th·ªã 5 video ƒë·∫ßu\n",
    "    df = pd.DataFrame(videos)\n",
    "    print(\"\\nüì∫ 5 video ƒë·∫ßu ti√™n:\")\n",
    "    print(df[['title', 'channelTitle', 'view_count', 'likes']].head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªñI: {e}\")\n",
    "    print(\"\\nüí° Ki·ªÉm tra:\")\n",
    "    print(\"   1. API_KEY c√≥ ƒë√∫ng kh√¥ng?\")\n",
    "    print(\"   2. API YouTube Data v3 ƒë√£ ƒë∆∞·ª£c b·∫≠t?\")\n",
    "    print(\"   3. Quota API c√≤n kh√¥ng?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä T·ªïng s·ªë videos trong CSV: 264767\n",
      "\n",
      "üîù Top 5 videos c√≥ view cao nh·∫•t:\n",
      "                               title  view_count     likes channelTitle\n",
      "262117  Discord Loot Boxes are here.  1407643634    126926      Discord\n",
      "262318  Discord Loot Boxes are here.  1406329649    165173      Discord\n",
      "261917  Discord Loot Boxes are here.   628718636     47460      Discord\n",
      "148718  BLACKPINK - ‚ÄòPink Venom‚Äô M/V   277791741  12993894    BLACKPINK\n",
      "148498  BLACKPINK - ‚ÄòPink Venom‚Äô M/V   273162966  12937252    BLACKPINK\n",
      "\n",
      "üìÖ Kho·∫£ng th·ªùi gian:\n",
      "  M·ªõi nh·∫•t: 2025-11-19 10:12:08+00:00\n",
      "  C≈© nh·∫•t: 2020-08-12 00:00:00+00:00\n",
      "\n",
      "üÜï Top 5 videos m·ªõi nh·∫•t:\n",
      "                   trending_date  \\\n",
      "264766 2025-11-19 10:12:08+00:00   \n",
      "264729 2025-11-19 10:12:08+00:00   \n",
      "264739 2025-11-19 10:12:08+00:00   \n",
      "264738 2025-11-19 10:12:08+00:00   \n",
      "264737 2025-11-19 10:12:08+00:00   \n",
      "\n",
      "                                                    title      channelTitle  \\\n",
      "264766  Family Guy 2025 Holiday Special | Official Tra...              Hulu   \n",
      "264729           Shinedown - Searchlight (Official Video)         Shinedown   \n",
      "264739  Wake Up Dead Man: A Knives Out Mystery | Offic...           Netflix   \n",
      "264738                                         Fine Chiki  JNR VIGI - Topic   \n",
      "264737  I Built A Brainrot AUTO PRINTER To Troll My Fr...  Doodle and Arkey   \n",
      "\n",
      "        view_count  \n",
      "264766       34178  \n",
      "264729       93333  \n",
      "264739     3246810  \n",
      "264738       83413  \n",
      "264737      110069  \n"
     ]
    }
   ],
   "source": [
    "# Xem data v·ª´a crawl\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "print(f\"\\nüìä T·ªïng s·ªë videos trong CSV: {len(df)}\")\n",
    "print(f\"\\nüîù Top 5 videos c√≥ view cao nh·∫•t:\")\n",
    "print(df.nlargest(5, 'view_count')[['title', 'view_count', 'likes', 'channelTitle']])\n",
    "\n",
    "# Parse date v√† chu·∫©n h√≥a timezone\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'], format='mixed', errors='coerce', utc=True)\n",
    "df_sorted = df.sort_values('trending_date', ascending=False)\n",
    "\n",
    "print(f\"\\nüìÖ Kho·∫£ng th·ªùi gian:\")\n",
    "print(f\"  M·ªõi nh·∫•t: {df_sorted['trending_date'].iloc[0]}\")\n",
    "print(f\"  C≈© nh·∫•t: {df_sorted['trending_date'].iloc[-1]}\")\n",
    "\n",
    "print(f\"\\nüÜï Top 5 videos m·ªõi nh·∫•t:\")\n",
    "print(df_sorted.head(5)[['trending_date', 'title', 'channelTitle', 'view_count']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
