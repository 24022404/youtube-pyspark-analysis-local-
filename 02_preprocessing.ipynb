{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SETUP \n",
    "import os\n",
    "import sys\n",
    "\n",
    "# # Set Java (SỬA PATH NÀY!)\n",
    "os.environ['JAVA_HOME'] = 'C:\\\\Java\\\\jdk-1.8'\n",
    "\n",
    "# # QUAN TRỌNG: Bypass Hadoop requirement\n",
    "os.environ['HADOOP_HOME'] = os.environ.get('JAVA_HOME')\n",
    "os.environ['PATH'] = f\"{os.environ['JAVA_HOME']}\\\\bin;{os.environ.get('PATH', '')}\"\n",
    "\n",
    "print(f\"JAVA_HOME: {os.environ['JAVA_HOME']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALL FINDSPARK\n",
    "!pip install pyspark findspark -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khởi tạo Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE SPARK SESSION\n",
    "import tempfile\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"YouTubePreprocessing\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", tempfile.gettempdir()) \\\n",
    "    .config(\"spark.ui.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(f\"Spark {spark.version} started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = spark.read.csv(\"./data/raw_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Kiểm tra format trending_date để hiểu dữ liệu\n",
    "print(\"=== SAMPLE TRENDING_DATE VALUES ===\")\n",
    "raw_df.select(\"trending_date\").filter(col(\"trending_date\").isNotNull()).distinct().show(10, False)\n",
    "\n",
    "print(\"RAW DATA OVERVIEW\")\n",
    "raw_df.show(5)\n",
    "\n",
    "print(\"VALID VIDEO ROWS (có video_id)\")\n",
    "valid_videos = raw_df.filter(col(\"video_id\").isNotNull() & (col(\"video_id\") != \"\"))\n",
    "print(f\"Valid videos: {valid_videos.count()} / {raw_df.count()}\")\n",
    "valid_videos.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiểm tra các giá trị trending_date không hợp lệ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INVALID TRENDING_DATE VALUES\")\n",
    "raw_df.select(\"trending_date\").filter(\n",
    "    col(\"trending_date\").isNotNull() & \n",
    "    ~col(\"trending_date\").rlike(r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}Z$\")\n",
    ").distinct().show(20, False)\n",
    "\n",
    "print(\"COUNT COMPARISON\")\n",
    "valid_dates = raw_df.filter(col(\"trending_date\").rlike(r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}Z$\")).count()\n",
    "total_with_dates = raw_df.filter(col(\"trending_date\").isNotNull()).count()\n",
    "print(f\"Valid dates: {valid_dates} / {total_with_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khai báo hàm dataframe_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def dataframe_info(df):\n",
    "    print(f\"{'-'*40}\")\n",
    "    print(f\"Số dòng: {df.count()}, Số cột: {len(df.columns)}\")\n",
    "    print(f\"{'-'*40}\")\n",
    "    df.printSchema()\n",
    "    print(f\"{'-'*40}\")\n",
    "    df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "dataframe_info(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1, Xóa các cột không cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = raw_df.drop('thumbnail_link', 'comments_disabled', 'video_error_or_removed', 'ratings_disabled')\n",
    "dataframe_info(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2, Xóa các hàng có tất cả giá trị là Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocessed_data.filter(\n",
    "    reduce(lambda a, b: a | b, (col(c).isNotNull() for c in preprocessed_data.columns))\n",
    ")\n",
    "dataframe_info(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_info(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3, Xóa các hàng có trending_date sai định dạng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lọc dữ liệu video hợp lệ - chỉ giữ những dòng có trending_date đúng format\n",
    "print(\"Before filtering:\")\n",
    "print(f\"Total rows: {preprocessed_data.count()}\")\n",
    "\n",
    "# Lọc chỉ những dòng có trending_date đúng format ISO timestamp\n",
    "preprocessed_data = preprocessed_data.filter(\n",
    "    col(\"trending_date\").rlike(r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}Z$\")\n",
    ")\n",
    "\n",
    "print(\"After filtering:\")\n",
    "print(f\"Valid rows: {preprocessed_data.count()}\")\n",
    "dataframe_info(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4, Điền giá trị Null cho description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocessed_data.fillna({\"description\": \"No description\"})\n",
    "dataframe_info(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5, Chuẩn hóa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi timestamp - SỬA FORMAT CHO ĐÚNG\n",
    "preprocessed_data = preprocessed_data.withColumn('trending_date', to_timestamp('trending_date', \"yyyy-MM-dd'T'HH:mm:ss'Z'\"))\n",
    "preprocessed_data = preprocessed_data.withColumn('publishedAt', to_timestamp('publishedAt', \"yyyy-MM-dd'T'HH:mm:ss'Z'\"))\n",
    "\n",
    "# Dataset riêng cho machine learning\n",
    "ML_data = preprocessed_data\n",
    "ML_data = ML_data.withColumn('tags', when(col('tags') == '[none]', '').otherwise(col('tags')))\n",
    "ML_data = ML_data.withColumn('tags', split(regexp_replace('tags', '\"', ''), '\\\\|'))\n",
    "\n",
    "preprocessed_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_info(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lưu dữ liệu đã xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps to string để tránh lỗi khi save\n",
    "preprocessed_save = preprocessed_data.withColumn('trending_date', \n",
    "    date_format('trending_date', 'yyyy-MM-dd HH:mm:ss')) \\\n",
    "    .withColumn('publishedAt', \n",
    "    date_format('publishedAt', 'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "ML_save = ML_data.withColumn('trending_date', \n",
    "    date_format('trending_date', 'yyyy-MM-dd HH:mm:ss')) \\\n",
    "    .withColumn('publishedAt', \n",
    "    date_format('publishedAt', 'yyyy-MM-dd HH:mm:ss'))\n",
    "\n",
    "# Lưu files\n",
    "preprocessed_save.toPandas().to_csv('./data/preprocessed_data.csv', index=False)\n",
    "ML_save.toPandas().to_csv('./data/ml_data.csv', index=False)\n",
    "print(\"Dữ liệu đã được lưu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
